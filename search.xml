<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>transformer学习记录</title>
      <link href="/2025/03/10/transformer%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
      <url>/2025/03/10/transformer%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h2 id="transformer学习记录"><a href="#transformer学习记录" class="headerlink" title="transformer学习记录"></a>transformer学习记录</h2><h3 id="1-注意力机制"><a href="#1-注意力机制" class="headerlink" title="1. 注意力机制"></a>1. 注意力机制</h3><p><strong>重点</strong>：<strong>词嵌入机制</strong>（embeddings）</p><h4 id="1-1-embeddings机制"><a href="#1-1-embeddings机制" class="headerlink" title="1.1 embeddings机制"></a>1.1 embeddings机制</h4><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503102107397.png" alt="image-20250310210751327"></p><p>对于上述遇到的一些具体歧义的单词时，如Apple，既可以代表水果，也可以代表苹果品牌。传统的embeddings技术如onehot和wordvector很难去进行区分具有歧义的单词，在创建好的词嵌入矩阵中，一个词只能用一个预训练好的向量去表示。</p><h4 id="1-2-Attention机制"><a href="#1-2-Attention机制" class="headerlink" title="1.2 Attention机制"></a>1.2 Attention机制</h4><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503102114788.png" alt="image-20250310211423751"></p><p>第一句中的Apple代表水果中的苹果，而第二句中代表的是品牌中的苹果。</p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503102120828.png" alt="image-20250310212005727"></p><p>第一句中的苹果更倾向于水果类，因此我们将苹果的坐标向水果类移动；第二句中的水果倾向于电子产品类，因此向手机的坐标移动。</p><p>Attention的操作就是对句子作一个并行处理。在开始时进行一个初始坐标赋值全部打乱，然后计算句子中的单词相似度来调整坐标，当两个单词意思相近时，他们之间的权重就越大，例如orange和apple。</p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503102135998.png" alt="image-20250310213518916"></p><p>类似于聚类的感觉，将其向水果类拉近。</p><p><strong>多头注意力机制 Multi-head attention</strong>：假设我们现在初始化三个embedding矩阵，可以很明显看到第一个矩阵的初始化效果更好，apple这个词在手机和水果分类的中间，apple离两种歧义分的越开，那么他的效果就更好，运行效率更好，多头注意力机制就是找出这样一个最佳的原始词嵌入矩阵，此时我们遇到的新问题就是取多少个矩阵更合适。多头注意力机制并不在纵向上叠加来拉升注意力机制的维度，而在横向添加来进行并行处理。<strong>通过拆分特征维度到多个子空间（多头），实现特征学习的多样性和并行化，最后通过线性层进行融合。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503102137786.png" alt="image-20250310213752725"></p><p>我们可以通过线性变换来进行变换</p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503102144895.png" alt="image-20250310214406820"></p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503102144528.png" alt="image-20250310214453461"></p><p>左边是多头注意力机制的架构图，右边是上述的过程。我们首先初始化三个词嵌入矩阵，然后通过三个权重矩阵W^Q,W^K,W^V对输入进来的三个词嵌入矩阵进行线性变换得到Q,K,V</p><p><em>Q</em>&#x3D;<em>X</em>⋅<em>W**Q</em>,<em>K</em>&#x3D;<em>X</em>⋅<em>W**K</em>,<em>V</em>&#x3D;<em>X</em>⋅<em>W**V</em></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python</title>
      <link href="/2025/03/07/python%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
      <url>/2025/03/07/python%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h3 id="关于-init-py"><a href="#关于-init-py" class="headerlink" title="关于__ init __.py"></a>关于__ init __.py</h3><p>假设现在有如下结构</p><p>project-name&#x2F;<br>│<br>├──package<br>│   ├── __ init __.py<br>│   └── a.py<br>│<br>├──b.py</p><p>现在a.py的内容为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;hello world!&quot;)</span><br></pre></td></tr></table></figure><p>b.py内容为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import package</span><br></pre></td></tr></table></figure><p>此时运行b.py不会输出任何内容，而此时我们在__ init __.py中加入如下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;hello world!&quot;)</span><br></pre></td></tr></table></figure><p>此时我们再次运行b.py，会看到终端窗口输出hello world!</p><p>这说明我们在<code>import package</code>时调用的package文件夹时，默认运行的是__ init __ .py文件。</p><p>当一个目录包含 <code>__init__.py</code> 时，Python 会将其视为一个“包”（Package），而非普通目录。这使得你可以通过 <code>import 包名.模块名</code> 的方式导入模块。</p><p>作用主要分三类：1.包的初始化；2.管理包接口；3.包的信息</p><p>参考：<a href="https://www.bilibili.com/video/BV1QA94YPEMK/?spm_id_from=333.1007.top_right_bar_window_default_collection.content.click&vd_source=da89301766d2e999eee1ad133fd0a648">https://www.bilibili.com/video/BV1QA94YPEMK/?spm_id_from=333.1007.top_right_bar_window_default_collection.content.click&amp;vd_source=da89301766d2e999eee1ad133fd0a648</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>模型剪枝</title>
      <link href="/2025/03/07/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/"/>
      <url>/2025/03/07/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/</url>
      
        <content type="html"><![CDATA[<table><thead><tr><th align="left"><strong>符号</strong></th><th align="left"><strong>定义</strong></th><th align="center"><strong>在 PruneFL 中的角色</strong></th></tr></thead><tbody><tr><td align="left"><strong>⊙</strong></td><td align="left">两个向量的逐元素乘积</td><td align="center">用于掩码操作，例如将参数向量与掩码向量相乘，保留重要参数，剪枝不重要参数。</td></tr><tr><td align="left"><strong>n, N</strong></td><td align="left">客户端索引（单个设备）、客户端总数</td><td align="center">表示参与联邦学习的边缘设备，N 是设备总数，用于分布式训练和参数聚合。</td></tr><tr><td align="left"><strong>k, K</strong></td><td align="left">迭代索引（通信轮次）、总迭代次数</td><td align="center">表示联邦学习的通信轮次，k 是当前轮次，K 是训练总轮次。</td></tr><tr><td align="left"><strong>I</strong></td><td align="left">本地迭代次数（每个客户端的 SGD 步骤数）</td><td align="center">客户端在本地数据上进行的参数更新次数，影响本地计算开销和模型收敛速度。</td></tr><tr><td align="left"><strong>pₙ</strong></td><td align="left">客户端 n 的聚合权重</td><td align="center">用于服务器聚合客户端参数时的加权平均，例如根据客户端数据量分配权重。</td></tr><tr><td align="left"><strong>m(k)</strong></td><td align="left">第 k 次迭代中的权重掩码（所有客户端共享）</td><td align="center">动态剪枝的关键，掩码中 0 表示参数被剪枝，1 表示保留。通过自适应策略更新，减少模型大小和通信开销。</td></tr><tr><td align="left"><strong>wₙ(k)</strong></td><td align="left">客户端 n 在第 k 次迭代时的本地参数</td><td align="center">客户端本地训练后的模型参数，上传至服务器进行聚合。</td></tr><tr><td align="left"><strong>w(k)</strong></td><td align="left">全局参数（加权平均）</td><td align="center">服务器聚合后的全局模型参数，下发至各客户端进行下一轮训练。</td></tr><tr><td align="left"><strong>w’ₙ(k), w’(k)</strong></td><td align="left">剪枝后的参数</td><td align="center">应用掩码后的稀疏参数，仅保留重要参数，用于减少计算和通信负载。</td></tr><tr><td align="left"><strong>gₙ(w)</strong></td><td align="left">客户端 n 在参数 w 处的随机梯度（w为模型参数向量）</td><td align="center">本地 SGD 计算的梯度，用于更新本地参数。在剪枝中可能用于评估参数重要性。</td></tr><tr><td align="left"><strong>∇Fₙ(w)</strong></td><td align="left">客户端 n 在参数 w 处的期望梯度</td><td align="center">理论上的平均梯度，与随机梯度相对，用于收敛性分析。</td></tr><tr><td align="left"><strong>∇F(w)</strong></td><td align="left">全局期望梯度</td><td align="center">全局模型的梯度方向，指导参数更新。在剪枝中可能用于优化掩码选择策略。</td></tr></tbody></table><p>模型剪枝也叫模型稀疏化，即将部分对网络贡献较小的特征剔除或者置0，稀疏化可以分为两类：权重稀疏化（将网络中某些权重值设为0或删除，通过L1正则化或剪枝技术）和结构稀疏化（神经元剪枝）。模型中可以被剪枝（稀疏）的对象通常为权重、神经元（激活函数）、梯度。可以认为模型稀疏或剪枝的方法为置0和删除，个人认为稀疏对应置0，剪枝对应删除。</p><h4 id="1-权重稀疏"><a href="#1-权重稀疏" class="headerlink" title="1. 权重稀疏"></a>1. 权重稀疏</h4><p>通常认为权重的绝对值大小是一种重要的衡量指标，权重数值越大代表对网络的输出贡献也越大，反之则不重要，删去对网络的影响也较小。</p><p>通常通过L1、L2正则化来迫使一些权重趋向于0，将一些低于阈值的权重参数删除，反复迭代这个删除过程知道模型的规模和精度达到预期。因为即使移除绝对值接近0的权重也会导致推理精度的损失，所以通常在剪枝后需要再训练。剪枝常做的三段式工作：训练、剪枝、微调。</p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/20250307213104479.png"></p><h4 id="2-神经元（激活函数）稀疏"><a href="#2-神经元（激活函数）稀疏" class="headerlink" title="2. 神经元（激活函数）稀疏"></a>2. 神经元（激活函数）稀疏</h4><p>首先这里给出现代网络常用激活函数ReLU函数的定义：<code>ReLU(x)=max(0,x)</code>，负值的输入都会被置为0，这种方法也可以认为是通过激活函数的方法给网络进行稀疏化。同样池化操作也可以产生类似形式，受此现象启发，我们发现CNN中许多的神经元都是低激活状态的，因此我们认为<strong>零神经元</strong>可能是冗余的，可以在不影响整体网络精度的情况下移除，即对网络中的神经元进行剪枝，做移除神经元操作。</p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/20250307212857550.png"></p><h4 id="3-梯度稀疏"><a href="#3-梯度稀疏" class="headerlink" title="3. 梯度稀疏"></a>3. 梯度稀疏</h4><p>通常采用选择固定比例的正负梯度更新或预设阈值。</p><p><strong>深度梯度压缩</strong>：在梯度稀疏化基础上采用动量修正、本地梯度剪裁、动量因子遮蔽和 warm-up训练 4 种方法来做梯度压缩，从而减少分布式训练中的通信带宽。</p><p>神经网络的权重、激活和梯度稀疏性总结：</p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/20250307213200481.png"></p><h4 id="4-结构化稀疏"><a href="#4-结构化稀疏" class="headerlink" title="4. 结构化稀疏"></a>4. 结构化稀疏</h4><p>分为Channel&#x2F;Filter 剪枝或shape-wise 剪枝，即对网络的层数（滤波器）或网络的大小进行剪裁。channel 剪枝的工作是最多的，channel 剪枝和 filter 剪枝其实意义是一样的，一个过滤器移除了，对应输出 feature map 的一个通道自然也被移除，反之一样。</p><p><strong>阶段式剪枝</strong>：可以弥补滤波器级剪枝的不足，如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503072144121.jpg" alt="v2-9666cdccffe0dd988c1796049073d4eb_1440w"></p><p>图中N1、N2等代表的是每一层实际保留的通道数，如a)原始模型有64个通道，b)中删减为了N1个。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文 </tag>
            
            <tag> 联邦学习 </tag>
            
            <tag> 模型剪枝 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo主题美化设置</title>
      <link href="/2025/03/02/hexo%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E8%AE%BE%E7%BD%AE/"/>
      <url>/2025/03/02/hexo%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E8%AE%BE%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="hexo主题美化设置"><a href="#hexo主题美化设置" class="headerlink" title="hexo主题美化设置"></a>hexo主题美化设置</h2><p>hexo下的相关配置分为主站配置和对应的主题配置文件。以本项目为例：项目配置文件在主路径&#x2F;blog下的_config.yml，而和主题相关配置的文件在&#x2F;blog&#x2F;themes&#x2F;hexo-theme-matery下的_config.yml中。</p><p>简单来说，我们可以认为当我们需要改变和当前主题的有关配置时（如美化，更换背景、主题的文字和标签分类），我们可以到主题的配置文件中去寻找。而当我们需要去更改一些全局配置时（如标签页的文字，网站的语言和主标题），我们应当到主站的配置文件中去寻找。</p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在mac上使用github + hexo 建立个人博客</title>
      <link href="/2025/03/02/github%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%99/"/>
      <url>/2025/03/02/github%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<h1 id="mac上使用github-hexo建立个人博客"><a href="#mac上使用github-hexo建立个人博客" class="headerlink" title="mac上使用github + hexo建立个人博客"></a>mac上使用github + hexo建立个人博客</h1><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><p>需要一个github账号和科学上网环境，所有操作推荐在<code>sudo su</code>的root环境下进行</p><h2 id="2-github上的相关配置"><a href="#2-github上的相关配置" class="headerlink" title="2. github上的相关配置"></a>2. github上的相关配置</h2><h3 id="2-1-建立博客的存储仓库"><a href="#2-1-建立博客的存储仓库" class="headerlink" title="2.1 建立博客的存储仓库"></a>2.1 建立博客的存储仓库</h3><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503021627761.png"></p><p>在github上建立一个<strong>公开仓库</strong>（一定要为<strong>公开</strong>），在<strong>repository name</strong>处填入username.github.io（username为前面owner下的id，注意一定要和前面一样，可以不区分大小写），随后建立仓库</p><p>补充：推荐创建两个仓库，一个公有，一个私有。部署网页的公开仓库和本地项目文件不一样，上传到该仓库的只有静态网页文件，不包含本地的整个项目文件，更换设备进行维护时会很不方便。</p><h3 id="2-2-SSH-key配置"><a href="#2-2-SSH-key配置" class="headerlink" title="2.2 SSH key配置"></a>2.2 SSH key配置</h3><p><img src="https://cdn.jsdelivr.net/gh/FeiZao825/picture-bed@main/img/202503021652121.png"></p><p>在设置中的<strong>SSH and GPG keys</strong>选项下选择<strong>New SSH key</strong>。此处需要注意的是mac系统在非root用户权限下ssh密钥的相关配置是独立的，推荐使用sudo su进入临时root权限后再新建一对ssh密钥，将该密钥下的id_rsa.pub中的ssh key填入此界面，否则在之后推送到仓库时可能会出现public key的问题。</p><h2 id="3-安装node-js"><a href="#3-安装node-js" class="headerlink" title="3. 安装node.js"></a>3. 安装node.js</h2><ol><li><p>官网选择macos和arm64或者打开终端输入：<code>curl https://raw.github.com/creationix/nvm/master/install.sh | sh</code></p></li><li><p>终端输入node -v &#x2F; npm -v，显示版本号即安装成功</p></li></ol><h2 id="4-安装hexo"><a href="#4-安装hexo" class="headerlink" title="4.安装hexo"></a>4.安装hexo</h2><p>终端输入：<code>sudo npm install hexo-cli -g</code></p><h2 id="5-使用hexo创建博客"><a href="#5-使用hexo创建博客" class="headerlink" title="5.使用hexo创建博客"></a>5.使用hexo创建博客</h2><ol><li>使用hexo初始化一个叫blog的文件夹并切换到blog文件夹：<code>hexo init blog &amp;&amp; cd blog</code></li><li>安装hexo-deployer-git自动部署发布工具：<code>npm install hexo-deployer-git --save</code></li><li>进入<em>\Users\apple\blog</em>文件夹，找到*_config.yml*文件，将文件底部的：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: </span><br></pre></td></tr></table></figure><p>替换成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">type: git</span><br><span class="line">  repo: git@github.com:FeiZao825/FeiZao825.github.io.git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure><h2 id="5-预览并发布博客"><a href="#5-预览并发布博客" class="headerlink" title="5.预览并发布博客"></a>5.预览并发布博客</h2><ol><li><p>生成网页静态文件到默认的<strong>public</strong>文件夹中：<code>hexo g</code></p></li><li><p>运行在本地并预览网页：<code>hexo s</code>，可以在”<a href="https://localhost:4000"进行预览">https://localhost:4000&quot;进行预览</a></p></li><li><p>部署到github上实现远程访问：<code>hexo d</code>，运行成功后可以看到仓库中多了静态网页的项目文件并且可以通过“feizao825.github.io”来访问</p><p>注意：<code>hexo d</code>上传的代码只有静态网页文件，和本地<code>hexo init</code>的文件不一样，推荐再创建一个保存本地项目的私有仓库</p></li><li><p>清空一下缓存，有时候博客页面显示不正常也可以试试这个命令行：<code>hexo clean</code></p></li></ol><h2 id="6-更换主题"><a href="#6-更换主题" class="headerlink" title="6.更换主题"></a>6.更换主题</h2><p><code>git clone  项目地址</code></p><p>运行上述命令后，可在&#x2F;themes路径下看到主题的文件夹，此处以<strong>hexo-theme-matery</strong>主题为例。</p><p>在项目主路径&#x2F;blog下的_config.yml中配置</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># theme: landscape  默认主题</span></span><br><span class="line">theme: butterfly</span><br><span class="line"></span><br><span class="line">title: 肥皂的博客</span><br><span class="line">author: FeiZao</span><br><span class="line">language: zh<span class="literal">-CN</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电池论文记录</title>
      <link href="/2025/03/02/%E7%94%B5%E6%B1%A0%E8%AE%BA%E6%96%87/"/>
      <url>/2025/03/02/%E7%94%B5%E6%B1%A0%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><p>**1.**电池采集原始数据（充放电电压，容量，IC曲线等）做特征工程，提取30个特征点</p><p>**2.**根据特征工程数据集通过同质或异质划分数据集，先对数据集添加噪声，随后将数据分发到各个客户端，客户端对数据进行重采样后进行本地训练。</p><ul><li><p>为了解决数据稀缺性问题，研究采用了<strong>数据增强</strong>技术。具体方法是对每个电池类别的数据进行重采样（Bootstrap），通过有放回采样的方式，增加每个类别的数据量，最终将每个类别的数据扩展到200条记录。</p></li><li><p><strong>高斯噪声添加</strong>：为了进一步保护隐私，并验证模型对噪声的鲁棒性，在增强后的数据上添加了随机高斯噪声，噪声强度由噪声-信号比（NSR）控制，范围从1%到10%。这种噪声的加入是为了评估模型在不同隐私预算下的表现。</p></li><li><p>数据集被分为训练集和测试集，分别按照80%和20%的比例进行划分。此外，在训练集中再进行40%的二次划分，用于交叉验证。</p></li><li><p>数据的划分采用分层抽样的方式，确保在每个客户端的数据样本分布中，各个电池类别都有足够的代表性。</p></li></ul><p><strong>同质 (Homogeneous)</strong></p><ul><li><strong>定义</strong>：同质集成指的是集成模型中的所有基学习器都是同一种类型的模型。在随机森林中，所有基学习器通常都是<strong>决策树</strong>，因此随机森林本身是一个<strong>同质集成模型</strong>。</li><li><strong>特点</strong>：虽然所有基学习器都是决策树，但通过对数据集进行不同的采样（即通过引入随机性，如数据采样和特征选择），每棵决策树的结构和预测结果可能会有所不同。这种通过随机性引入的差异使得同质集成的模型在一定程度上具有多样性。</li></ul><p><strong>例子</strong>：</p><ul><li>随机森林的每个基学习器都是决策树，虽然它们的模型形式相同，但由于每棵树基于不同的数据子集和特征子集构建，因此形成了同质集成。</li></ul><h5 id="异质-Heterogeneous"><a href="#异质-Heterogeneous" class="headerlink" title="异质 (Heterogeneous)"></a>异质 (Heterogeneous)</h5><ul><li><strong>定义</strong>：异质集成是指集成模型中的基学习器由不同类型的模型组成。在这种情况下，集成模型会结合多种不同类型的算法来构建。例如，你可以结合决策树、支持向量机（SVM）、神经网络、k近邻算法等模型。</li><li><strong>特点</strong>：由于不同类型的模型通常具有不同的假设和表现，异质集成模型能够通过结合不同的模型优势，提高整体的预测性能和稳健性。这种方法通常被称为“<strong>堆叠（stacking）</strong>”或“集成学习”的一种复杂形式。</li></ul><p><strong>例子</strong>：</p><ul><li>使用决策树、逻辑回归和支持向量机来创建一个集成模型。不同模型的预测结果可以通过投票、平均或堆叠来聚合。</li></ul><h4 id="区别总结："><a href="#区别总结：" class="headerlink" title="区别总结："></a>区别总结：</h4><ul><li><strong>同质集成</strong>：所有基学习器都是相同类型的模型（如随机森林中的所有树都是决策树）。</li><li><strong>异质集成</strong>：基学习器由不同类型的模型组成（如组合决策树、SVM、神经网络等）。</li></ul><p>随机森林是一种典型的<strong>同质集成模型</strong>，通过引入随机性（如随机选择特征和样本）来增加模型的多样性，从而提升整体表现。</p><p><strong>3.<strong>使用WDV投票机制，将每个客户端中的结果进行聚合，参与者上传给中心服务器的并不是随机森林模型的原始参数或训练数据，而是每个参与者在本地随机森林模型上</strong>预测的结果</strong>。随机森林的聚合通常是通过投票，平均法或bagging等方法对每个随机森林的最后预测结果进行聚合，以投票法为例，可以理解为取随机森林结果中概率最大的那个预测结果。</p><p><strong>本地模型训练与预测结果生成</strong></p><p>每个参与者使用本地数据集训练一个随机森林模型。这些随机森林模型基于本地数据进行训练，而不与其他参与者的数据共享。</p><ul><li>随机森林模型由多个决策树组成，参与者使用本地的电池数据进行训练，生成模型。</li><li>训练完毕后，参与者会根据本地模型对测试数据或实时数据做出预测，生成预测结果。</li></ul><p><strong>上传的内容：预测结果</strong></p><p>在联邦学习框架中，参与者并不上传原始数据或者完整的模型参数，而是上传经过模型计算的<strong>预测结果</strong>。这些预测结果可以是对给定输入数据的分类或回归输出。上传的预测结果通过加密保护，保证在传输过程中不会泄露原始数据。</p><p><strong>服务器聚合过程</strong></p><p>服务器接收到各个参与者的预测结果后，通过<strong>Wasserstein距离投票（WDV）</strong>或其他加权投票策略来对这些结果进行聚合。具体步骤如下：</p><ul><li>每个参与者上传的预测结果（如对电池类型的分类）被聚合时，服务器会根据每个参与者与全局模型之间的Wasserstein距离，计算该参与者的权重。</li><li>这些预测结果会通过加权投票的方式整合为最终的全局预测结果。服务器根据各个参与者的预测分布进行加权，得到最符合全局目标的分类结果。</li></ul><p><strong>聚合的目标</strong></p><p>这种聚合方式的目标是通过每个参与者的本地模型提供的预测结果，来生成一个全局模型或决策结果。与传统的模型参数聚合不同，论文采用的是基于各地预测结果的聚合，这样不仅保护了参与者的数据隐私，还能有效处理不同参与者之间的数据异构性问题。</p><p><strong>差分隐私保护</strong></p><p>为了进一步保障隐私，上传的预测结果会在发送之前经过差分隐私处理。例如，参与者会在预测结果上加入高斯噪声，确保即使服务器接收到这些预测结果，也无法还原回原始数据。这样可以有效防止数据泄露，同时保持较高的模型准确性。</p><p>**4.**加入隐私保护机制，通过高斯噪声实现，噪声主要是在模型上传阶段和数据增强阶段引入的。在本地训练完模型之后就会加入噪声，在上传到服务器前就会执行的步骤</p><p>手工实现adam，在adam中添加噪声实现隐私，可以在每个节点上添加噪声</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> 电池 </tag>
            
            <tag> 特征工程 </tag>
            
            <tag> 随机森林 </tag>
            
            <tag> 数据同质和异质性 </tag>
            
            <tag> 数据处理 </tag>
            
            <tag> 联邦学习 </tag>
            
            <tag> admm </tag>
            
            <tag> 隐私保护 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/02/23/hello-world/"/>
      <url>/2025/02/23/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>everything软件正则匹配规则</title>
      <link href="/2025/01/21/everything/"/>
      <url>/2025/01/21/everything/</url>
      
        <content type="html"><![CDATA[<h2 id="正则表达式重命名匹配规则"><a href="#正则表达式重命名匹配规则" class="headerlink" title="正则表达式重命名匹配规则"></a>正则表达式重命名匹配规则</h2><p>以“Steins_Gate S01E02]<a href="81BF513C">x264_flac</a>.mkv”为例，快速批量重命名文件为“Steins_Gate S01E02.mkv”</p><p>(Steins_Gate S01E\d+)[.*](.*).(mkv|sc.ass)提取两个括号中的内容，使用\d提取集数，提取mkv和sc.ass</p><p>\1.\2重命名文件，\1匹配上述第一个括号内的内容，\2匹配上述第二个括号.(mkv|sc.ass)的文件后缀</p>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件 </tag>
            
            <tag> everything </tag>
            
            <tag> nas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSH的相关使用</title>
      <link href="/2024/12/31/ssh/"/>
      <url>/2024/12/31/ssh/</url>
      
        <content type="html"><![CDATA[<h2 id="SSH连接密钥生成"><a href="#SSH连接密钥生成" class="headerlink" title="SSH连接密钥生成"></a>SSH连接密钥生成</h2><p>ssh-keygen -t rsa -b 4096 -C “feizao”</p><p><code>ssh-keygen</code> 是用于生成、管理和转换 SSH（Secure Shell）认证密钥的工具。 <code>ssh-keygen -t -rsa -b 4096 -C &quot;feizao&quot;</code> 的含义如下：</p><ul><li><code>-t rsa</code>：指定密钥类型为 RSA。</li><li><code>-b 4096</code>：设置密钥长度为 4096 位。</li><li><code>-C &quot;feizao&quot;</code>：为密钥添加注释 “feizao”。</li></ul><p>执行此命令后，系统会提示您指定保存密钥的位置&#x2F;root&#x2F;.ssh&#x2F;id_rs（默认情况下为 <code>~/.ssh/id_rsa</code>），以及设置用于保护私钥的密码短语（可以为空，但这会降低安全性）。 生成的密钥对包括一个私钥（仅您自己保存）和一个公钥（可分发给需要验证您身份的服务器）。</p><p>.pub指公钥，其功能是需要把它放到例如github、gitee之类的代码平台上，告诉我们这里有一扇门。我们需要使用本地的私钥来访问这扇门，即公钥-私钥的配对，公钥可以理解为门，私钥可以理解为门的钥匙。</p><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><p>git init 本地新建并初始化一个仓库</p><p>使用ssh方式git需要在本地.ssh中同时放入.pub和id_rsa，即公钥和私钥来访问私有仓库</p><p><strong>下载代码</strong></p><p>git clone <a href="mailto:&#x67;&#105;&#116;&#64;&#103;&#105;&#x74;&#101;&#101;&#46;&#99;&#111;&#x6d;">&#x67;&#105;&#116;&#64;&#103;&#105;&#x74;&#101;&#101;&#46;&#99;&#111;&#x6d;</a>:feizao1145&#x2F;gans-fed.git 获取远程仓库</p><p>git clone *** –depth 10 通过添加 –depth 10来指定获取最近10次的提交结果</p><p>[</p><p>git submodule update –init –recursive  对于一些很久的分支，要用这个更新一下子模块</p><p>git status 查看状态,确定一下是否有没有track的子模块</p><p>]</p><p><strong>提交代码</strong></p><p>git config –global user.email “<a href="mailto:&#x31;&#x33;&#54;&#56;&#x32;&#x39;&#x35;&#51;&#53;&#x39;&#x40;&#113;&#x71;&#46;&#99;&#x6f;&#x6d;">&#x31;&#x33;&#54;&#56;&#x32;&#x39;&#x35;&#51;&#53;&#x39;&#x40;&#113;&#x71;&#46;&#99;&#x6f;&#x6d;</a>“ 提交者邮箱</p><p>git config –global user.name “feizao” 提交者姓名</p><p>通过上述代码可以看到提交者是谁，通过git log查看提交记录</p><p>git checkout -b feizao&#x2F;1221_test 在现有分支（默认分支）上克隆创建一个新的分支，尽量用日期命名，过几天可以换一个新的分支来维护</p><p>TIPS:vscode中代码旁标绿或文件旁边有M(modify)代表该文件有修改</p><p>git add xxx.py 添加更改的文件到缓存区，最好是改一步就提交一次，不要一次性改完再提交</p><p>git commit -m “xxxx” 添加评论</p><p>截止目前的操作都在本地进行，下一步将本地操作上传到远程仓库</p><p>git push –set-upstream origin feizao&#x2F;1221_test 第一次提交创建的分支时需使用该命令来在远程仓库的origin原始仓库新建一个分支</p><p>也可以在vscode中选择当前的分支，在当前分支基础上生成一个新的分支</p><p>git reset –soft HEAD^ 将上次提交的代码回退，撤销本次修改 </p><h2 id="合并分支代码到master"><a href="#合并分支代码到master" class="headerlink" title="合并分支代码到master"></a>合并分支代码到master</h2><p>1.先从分支切换到master</p><p>​git checkout master</p><p>2.拉取远程master分支最新代码：合并前确保master分支本地与远程同步</p><p>​git pull origin master</p><p>3.合并分支（1221_test）到master</p><p>​git merge 1221_test 合并分支到当前所处分支</p><p>4.推送合并后的本地master分支到远程</p><p>​git push origin master</p><p>5.（可选）删除分支，假设该分支的开发任务已完成不需要了</p><p>​删除本地：git branch -d 1221_test</p><p>​删除远程：git push origin –delete 1221_test</p><h2 id="pytorch的一些记录"><a href="#pytorch的一些记录" class="headerlink" title="pytorch的一些记录"></a>pytorch的一些记录</h2><p>loss.backward() 这个函数并不针对具体哪个模型的某个参数，而是对loss这个变量中包含的所有参数进行求导来得到梯度，然后在通过optimizer.step()优化器来进行梯度更新，因此会对loss中所包含的所有参数梯度进行更新</p>]]></content>
      
      
      <categories>
          
          <category> ssh </category>
          
      </categories>
      
      
        <tags>
            
            <tag> github </tag>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DLADMM算法</title>
      <link href="/2024/10/20/dladmm/"/>
      <url>/2024/10/20/dladmm/</url>
      
        <content type="html"><![CDATA[<h2 id="3-DLADMM算法"><a href="#3-DLADMM算法" class="headerlink" title="3  DLADMM算法"></a>3  DLADMM算法</h2><h4 id="3-1"><a href="#3-1" class="headerlink" title="3.1"></a>3.1</h4><p>将原有的深度学习的目标即损失函数转化为一个优化问题</p><p>首先介绍了深度学习网络的基本结构以及反向传播算法，其次定义了优化问题1即损失函数，通过最小化损失函数来接近正确值，同时为了防止过拟合，引入了正则化项，为了确保优化过程中参数更新能够保持每一层之间的关系，引入了约束条件：线性约束与激活函数的约束。</p><p>松弛问题：<a href="https://blog.csdn.net/universsky2015/article/details/135796968">https://blog.csdn.net/universsky2015/article/details/135796968</a> </p><p>深度网络中涉及到非线性和高维的参数，直接求解优化问题较困难，因此引入了松弛定义来简化问题解决问题2，将问题1的约束条件进行了简化，通过松弛，问题的<strong>硬性约束</strong>被转化为<strong>惩罚项</strong>，并且并入了目标函数的一部分。这样，原本必须满足的约束条件现在只需要逐渐逼近就可以了。ADMM本身是一种将复杂优化问题拆分为若干个子问题分别求解的优化方法，松弛项的引入使得每个子问题都更加易于处理，从而提高了整体算法的效率。</p><h4 id="3-2-DLADMM算法"><a href="#3-2-DLADMM算法" class="headerlink" title="3.2 DLADMM算法"></a>3.2 DLADMM算法</h4><p>与传统的反向算法相比，在反向传播计算梯度更新权重和参数之后引入了向前传播再一次进行求梯度更新参数，这一步补充了传统BP算法的不足，特别是对前几层（靠近输入层）的调整更加及时，因为这几层在传统的BP中往往要等到误差传递过来之后才能更新。而向前更新能够让这些层更早地得到反馈信息，从而加快了模型的收敛速度。</p><p>admm的基础思想是将一个复杂的优化问题分为多个子问题。<strong>梯度下降</strong>主要用于<strong>无约束优化问题</strong>，即模型的目标是最小化一个损失函数，但没有特定的约束条件。<strong>ADMM</strong>更适合处理<strong>带有约束的优化问题</strong>，它通过引入拉格朗日乘子，将约束条件转化为可解的子问题。可以将admm理解为并行处理多个问题。惩罚函数的作用是将有约束转换为无约束</p><p>dlADMM的核心在于通过<strong>增广拉格朗日函数</strong>解决深度学习中的优化问题，并结合ADMM的方法将问题分解为多个小问题。增广拉格朗日函数用于处理神经网络的参数优化，并通过加入惩罚项来约束层与层之间的关系</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> dladmm </tag>
            
            <tag> 梯度更新 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
